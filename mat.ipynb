{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [5]\n",
      " [9]]\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n",
      "[[-6.38888889e-01 -5.55555556e-02  5.27777778e-01]\n",
      " [-1.66666667e-01  6.55053106e-17  1.66666667e-01]\n",
      " [ 3.05555556e-01  5.55555556e-02 -1.94444444e-01]]\n",
      "[[ 3.83333333]\n",
      " [ 1.33333333]\n",
      " [-1.16666667]]\n",
      "1\n",
      "[[1 4 0]\n",
      " [0 0 8]\n",
      " [3 0 0]]\n",
      "max\n",
      "max\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "a = np.array([[1,4,7],[2,5,8],[3,6,9]])\n",
    "A = np.matrix(a)\n",
    "c = np.array([1,5,9])\n",
    "C = np.matrix(c)\n",
    "print(C.transpose())\n",
    "print(A)\n",
    "print(np.linalg.pinv(a))\n",
    "print(np.dot(np.linalg.pinv(a),C.transpose()))\n",
    "\n",
    "for i in range(10,0,-1):\n",
    "    pass\n",
    "print(i)\n",
    "H1 = np.random.rand(*a.shape) < 0.5\n",
    "a *= H1 \n",
    "print(a)\n",
    "H2 = torch.randn(a.shape) < 0.5\n",
    "max = [0,1,2]\n",
    "for ly in range(1,5):\n",
    "    if ly in max:\n",
    "        print(\"max\")\n",
    "print(H2)\n",
    "w = 2**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False,  True,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 假设有一个 seq_len=4 的输入序列\n",
    "seq_len = 3\n",
    "\n",
    "# 创建 lookahead mask (upper triangular matrix)\n",
    "mask = torch.triu(torch.ones(2,seq_len, seq_len), diagonal=1)  # (seq_len, seq_len)\n",
    "mask = mask == 1  # 将上三角部分设为 True，其他部分为 False\n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2,10,4))\n",
    "\n",
    "y = torch.randn((2,10000,5000))\n",
    "y = torch.transpose(y,1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModule(\n",
      "  (linears): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(10, 10) for i in range(2)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x\n",
    "myModule = MyModule()\n",
    "print(myModule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0730],\n",
      "         [ 0.0955],\n",
      "         [ 0.2590],\n",
      "         [ 0.4164]],\n",
      "\n",
      "        [[ 1.1617],\n",
      "         [ 1.3078],\n",
      "         [ 1.4497],\n",
      "         [ 1.5883]]])\n",
      "tensor([[[1.3491],\n",
      "         [1.3236],\n",
      "         [1.3013],\n",
      "         [1.2830]],\n",
      "\n",
      "        [[0.8848],\n",
      "         [0.8737],\n",
      "         [0.8654],\n",
      "         [0.8592]]])\n",
      "tensor([[[0.2787],\n",
      "         [0.3180],\n",
      "         [0.3525],\n",
      "         [0.3809]],\n",
      "\n",
      "        [[0.9972],\n",
      "         [1.0143],\n",
      "         [1.0271],\n",
      "         [1.0367]]])\n",
      "tensor([[[1.3074],\n",
      "         [1.2820],\n",
      "         [1.2596],\n",
      "         [1.2413]],\n",
      "\n",
      "        [[0.8431],\n",
      "         [0.8321],\n",
      "         [0.8238],\n",
      "         [0.8176]]])\n",
      "tensor([[[-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619]],\n",
      "\n",
      "        [[-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619],\n",
      "         [-1.1619, -0.3873,  0.3873,  1.1619]]])\n",
      "LayerNorm Output: tensor([[[ 0.8637, -1.1573, -0.8205,  1.1142],\n",
      "         [ 0.3094,  1.3110, -1.4707, -0.1497],\n",
      "         [ 0.0654,  1.4371, -0.1181, -1.3844],\n",
      "         [-0.3612, -0.9250, -0.4026,  1.6887],\n",
      "         [-1.6309,  1.0536,  0.1107,  0.4665],\n",
      "         [ 0.8378,  0.2324, -1.6908,  0.6205],\n",
      "         [-0.5792, -0.8554, -0.2581,  1.6926],\n",
      "         [-0.8670, -1.1092,  0.8076,  1.1686],\n",
      "         [-0.2566, -0.0314,  1.5389, -1.2509],\n",
      "         [ 0.2360,  0.3406, -1.6415,  1.0648]],\n",
      "\n",
      "        [[ 0.9566, -0.8392,  1.0307, -1.1481],\n",
      "         [-1.4307,  1.3969,  0.0417, -0.0079],\n",
      "         [ 1.3031, -1.5079,  0.0430,  0.1618],\n",
      "         [ 0.5919, -1.0222, -0.9056,  1.3359],\n",
      "         [ 1.2375, -0.2210, -1.4835,  0.4670],\n",
      "         [-0.8733, -0.4422, -0.3854,  1.7009],\n",
      "         [-0.3758,  0.8568,  0.9860, -1.4670],\n",
      "         [ 0.4026,  0.4371, -1.7032,  0.8634],\n",
      "         [ 1.3761,  0.5317, -0.9979, -0.9098],\n",
      "         [ 1.5119, -1.2851,  0.0224, -0.2492]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1545],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547]],\n",
      "\n",
      "        [[1.1546],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1547],\n",
      "         [1.1546],\n",
      "         [1.1547],\n",
      "         [1.1546],\n",
      "         [1.1546],\n",
      "         [1.1547],\n",
      "         [1.1547]]], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 简单测试 LayerNorm\n",
    "out = torch.tensor([[[-1.6404, -0.5955,  0.4495,  1.4945],\n",
    "         [-1.4424, -0.4172,  0.6081,  1.6333],\n",
    "         [-1.2530, -0.2450,  0.7630,  1.7710],\n",
    "         [-1.0743, -0.0805,  0.9133,  1.9071]],\n",
    "\n",
    "        [[ 0.1337,  0.8191,  1.5044,  2.1897],\n",
    "         [ 0.2926,  0.9694,  1.6462,  2.3230],\n",
    "         [ 0.4441,  1.1145,  1.7848,  2.4552],\n",
    "         [ 0.5900,  1.2555,  1.9211,  2.5866]]])\n",
    "print(out.mean(dim=-1,keepdim=True))\n",
    "print(out.std(dim=-1,keepdim=True))\n",
    "out1 = torch.tensor([[[-1.2404, -0.2277,  0.7850,  1.7977],\n",
    "         [-1.1715, -0.1785,  0.8145,  1.8075],\n",
    "         [-1.1110, -0.1353,  0.8404,  1.8161],\n",
    "         [-1.0614, -0.0998,  0.8617,  1.8232]],\n",
    "\n",
    "        [[ 0.0176,  0.6707,  1.3237,  1.9768],\n",
    "         [ 0.0474,  0.6920,  1.3365,  1.9811],\n",
    "         [ 0.0699,  0.7080,  1.3461,  1.9842],\n",
    "         [ 0.0867,  0.7200,  1.3533,  1.9866]]])\n",
    "print(out1.mean(dim=-1,keepdim=True))\n",
    "print(out1.std(dim=-1,keepdim=True))\n",
    "print((out1-out1.mean(dim=-1,keepdim=True))/out1.std(dim=-1,keepdim=True))\n",
    "layer_norm = torch.nn.LayerNorm(4)  # 假设 emb_dim=4\n",
    "output = layer_norm(x)\n",
    "print(\"LayerNorm Output:\", output)\n",
    "print(output.std(dim=-1,keepdim=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    #x_ = torch.transpose(x,2,1)\n",
    "    #        out1 = self.Mutiheads(x,x,x)\n",
    "     #       #x_clone = x\n",
    "      #      #print(x + out1)\n",
    "       #     #print(\"out1:\\n\",out1)\n",
    "        #    #out1 = self.Mutiheads(x,x,x)\n",
    "         #   #print(\"Input to LayerNorm - Mean:\\n\",(x_clone+ out1).mean(dim=-1))\n",
    "         #   #print(\"Input to LayerNorm - Std:\\n\",(x_clone+ out1).std(dim=-1))\n",
    "         #   out2 = self.Layernorm1(out1 + x)\n",
    "         #   out2 = self.dropout(out2)\n",
    "          #  #out2 = self.Layernorm1(out2 + x_clone)\n",
    "            #print(\"(Layernorm)out2:\\n\",out2)\n",
    "          #  out3 = self.feedforward(out2)\n",
    "            #print(\"out3:\\n\",out3)\n",
    "            #out = self.dropout1(out3)\n",
    "           # out = self.Layernorm2(out2+out3)\n",
    "            #y = self.dropout(out)\n",
    "            #y = out\n",
    "            self.mlps = nn.ModuleList([\n",
    "            nn.Linear(inp_dim, hidden_dim_feedforward),  # First MLP layer\n",
    "            nn.ReLU(),                                  # ReLU activation\n",
    "            nn.Linear(hidden_dim_feedforward, inp_dim)   # Second MLP layer\n",
    "        ])\n",
    "        for mlp in self.mlps:\n",
    "            if isinstance(mlp, nn.Linear):  # Check if the module is a Linear layer\n",
    "                nn.init.xavier_normal_(mlp.weight)  # Xavier initialization for weights\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 2., 2., 2.])\n",
      "tensor([2., 2., 2., 2., 0.])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "dropout = nn.Dropout(p=0.5)  # 50% dropout rate\n",
    "x = torch.ones(5)\n",
    "\n",
    "# 模拟两次 Dropout\n",
    "y1 = dropout(x)  # 第一次 Dropout\n",
    "y2 = dropout(x)  # 第二次 Dropout\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6667, 1.6667, 1.6667, 1.6667, 1.6667])\n",
      "tensor([0.0000, 1.6667, 1.6667, 1.6667, 1.6667])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "mask = (torch.rand_like(x) > 0.5).float() / 0.5  # 生成 Dropout 掩码\n",
    "y1 = x * mask  # 应用相同的 Dropout 掩码\n",
    "y2 = x * mask  # 再次应用相同的 Dropout 掩码\n",
    "dropout_ = F.dropout(x,0.2)\n",
    "dropout_1 = F.dropout(x,0.2)\n",
    "print(dropout_)\n",
    "print(dropout_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5403,  0.5403,  0.5403],\n",
      "        [-0.4161, -0.4161, -0.4161],\n",
      "        [-0.9900, -0.9900, -0.9900],\n",
      "        [-0.6536, -0.6536, -0.6536]])\n",
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros((3))\n",
    "div_term = torch.pow(10000,-a)\n",
    "position = torch.arange(5).unsqueeze(1)\n",
    "print(torch.cos(position * div_term))\n",
    "print(div_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
